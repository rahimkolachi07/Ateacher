<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>🎤 Voice Bot Assistant</title>
  <style>
    body {
      font-family: 'Segoe UI', sans-serif;
      background: linear-gradient(to right, #74ebd5, #ACB6E5);
      margin: 0;
      padding: 0;
      overflow-x: hidden;
    }

    .container {
      max-width: 800px;
      margin: 50px auto;
      background: white;
      border-radius: 15px;
      box-shadow: 0 10px 25px rgba(0,0,0,0.1);
      padding: 20px;
      animation: fadeIn 1s ease-in;
    }

    h1 {
      text-align: center;
      color: #333;
      margin-bottom: 20px;
    }

    .chat-box {
      height: 400px;
      overflow-y: auto;
      border: 1px solid #ccc;
      padding: 15px;
      border-radius: 10px;
      background: #f9f9f9;
      margin-bottom: 20px;
    }

    .message {
      margin: 10px 0;
      animation: fadeIn 0.4s ease;
    }

    .message.user { text-align: right; color: #007bff; }
    .message.bot { text-align: left; color: #333; }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>🤖 Live AI Teacher Talk</h1>
    <div class="chat-box" id="chatBox"></div>
  </div>

<script>
  const chatBox = document.getElementById('chatBox');

  // Automatically start listening when the page loads
  window.onload = () => startVoiceRecognition();

  function addMessage(message, sender) {
    const div = document.createElement('div');
    div.className = `message ${sender}`;
    div.innerText = message;
    chatBox.appendChild(div);
    chatBox.scrollTop = chatBox.scrollHeight;

    if (sender === 'bot') speak(message);
  }

  function speak(text) {
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'en-US';
    speechSynthesis.speak(utterance);
  }

  function startVoiceRecognition() {
    if (!navigator.mediaDevices || !window.MediaRecorder) {
      alert("Your browser doesn't support Web Audio.");
      return;
    }

    navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
      const mediaRecorder = new MediaRecorder(stream);
      let chunks = [];

      mediaRecorder.start();

      mediaRecorder.ondataavailable = e => chunks.push(e.data);

      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(chunks, { type: 'audio/wav' });
        sendToServer(audioBlob);
        chunks = [];
      };

      setInterval(() => {
        mediaRecorder.stop();
        mediaRecorder.start(); // restart recording every 5 seconds
      }, 5000);
    });
  }

  // Function to get the CSRF token from the document
  function getCSRFToken() {
    const csrfToken = document.querySelector('[name=csrfmiddlewaretoken]').value;
    return csrfToken;
  }

  function sendToServer(blob) {
    addMessage("🎙️ Listening...", "user");

    const formData = new FormData();
    formData.append('audio', blob, 'recording.wav');

    fetch('/process-audio/', {
      method: 'POST',
      headers: {
        'X-CSRFToken': getCSRFToken()  // Add CSRF token to the header
      },
      body: formData
    })
    .then(response => response.json())
    .then(data => {
      addMessage(data.response, 'bot');
    })
    .catch(error => {
      console.error('Error:', error);
      addMessage("Sorry, couldn't process your voice.", 'bot');
    });
  }
</script>

</body>
</html>
